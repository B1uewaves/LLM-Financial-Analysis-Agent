#####
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
.\.venv\Scripts\Activate.ps1

streamlit run main.py

docker-compose down
docker-compose up --build -d

http://localhost:8501

scp -i llm.pem -r * ubuntu@13.51.206.118:~/llm-agent
ssh -i llm.pem ubuntu@13.51.206.118

then on ec2: 
cd ~/llm-agent
docker compose down        # stop old container
docker compose up --build  # rebuild with new code

docker system prune -a -f --volumes
df -h




http://13.51.206.118:8501


python -m tools.summary_tool 

# LangChain Stock & News Agent

## Overview
A lightweight Streamlit app + LangChain agent that fetches realâ€‘time stock data (via yfinance), summarizes news with OpenAI, and provides basic price forecasts.

## Features
- âœ… Live stock quotes & charts
- ğŸ§  LLMâ€‘powered company news summaries
- ğŸ”® MLâ€‘based shortâ€‘term price forecasts
- â˜ï¸ Deployable to Hugging Face Spaces

## Project Structure
```text
project/
â”œâ”€â”€ agent.py
â”œâ”€â”€ main.py
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ stock_tool.py   
â”‚   â”œâ”€â”€ summary_tool.py
â”‚   â”œâ”€â”€ news_tool.py
â”‚   â””â”€â”€ forecast_tool.py
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ templates.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .huggingface.yaml
â””â”€â”€ README.md
```

## Getting Started
1. Clone the repo
2. Create & activate your virtualenv
3. Copy `.env.example` â†’ `.env` and fill in your API keys
4. `pip install -r requirements.txt`
5. `streamlit run main.py`

+-------------------+
|    main.py        |  <-- Streamlit UI, entry point
+-------------------+
          |
          v
+-------------------+         +-------------------+
| stock_tool.py     |         | news_tool.py      |
| fetch_stock_data  |         | fetch_headlines   |
+-------------------+         +-------------------+
          |                           |
          +-----------+---------------+
                      |
                      v
             +-------------------+
             | ingest_tool.py    |  <-- Ingests headlines, builds vector index
             | ingest_headlines  |
             +-------------------+
                      |
                      v
             +-------------------+
             | retrieval_tool.py |  <-- Builds/queries FAISS vector store
             | init_vector_store |
             | retrieve          |
             +-------------------+
                      |
                      v
             +-------------------+
             | vector_store.py   |  <-- Loads/saves FAISS index
             | load_vector_store |
             +-------------------+
                      |
                      v
             +-------------------+
             | vector_index/     |  <-- Persisted vector data
             +-------------------+

          |
          v
+-------------------+
| summary_tool.py   |  <-- LLM summary, uses OpenAI
| summarize         |
+-------------------+
          ^
          |
+-------------------+
| prompts/          |  <-- Prompt templates (YAML, .py)
+-------------------+

Layer 1: Data Ingestion
  â†³ ingest_tool.py         â†’ Handles embedding + indexing

Layer 2: Vector Store Manager (ISOLATED HERE) âœ…
  â†³ vector_store.py        â†’ Load, retrieve, save, inspect (generic interface)

Layer 3: Applications
  â†³ summary_tool.py        â†’ Uses retrieve() + summarize()
  â†³ headline_tool.py       â†’ Uses retrieve() + prints titles/snippets


Browser Tab
  |
  |-- st.session_state["session_id"] = "session-123"
  |-- st.session_state["agent"] = build_agent(memory)
  |
Streamlit Server (main.py reruns on input)
  |
  |-- get_memory("session-123") â†’ RedisChatMessageHistory
  |
  |-- agent.run("What changed since last time?")
  |
Redis
  |
  |-- Key: "session-123"
  |-- Value: [ {user: "Show TSLA"}, {AI: "TSLA is up 5%..."} ]